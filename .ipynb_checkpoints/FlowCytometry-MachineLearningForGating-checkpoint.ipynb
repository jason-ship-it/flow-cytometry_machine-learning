{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FlowCytometryTools as flow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "Data handling: [http://eyurtsev.github.io/FlowCytometryTools/tutorial.html](http://eyurtsev.github.io/FlowCytometryTools/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading a file\n",
    "datafile = \"data/JF2017-01-06-B.0006.fcs\"\n",
    "sample = flow.FCMeasurement(ID='MG1655_sfGFP_mRFP1', datafile=datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examining channels in the file\n",
    "print sample.channel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YourSample.data returns a pandas dataframe with the raw data for each read\n",
    "# I gatered 10k reads, 13 channels\n",
    "print sample.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample.data['B1-A'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And here's some data\n",
    "print sample.data[['Y2-A', 'FSC-A']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For retrieving the median\n",
    "print sample.data['Y2-A'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Plotting gallery: [http://eyurtsev.github.io/FlowCytometryTools/gallery.html](http://eyurtsev.github.io/FlowCytometryTools/gallery.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample.plot('B1-A', color='#2F57FF', alpha=0.9, bins=100, grid=True)\n",
    "plt.axvline(250, c=\"#D62750\", linestyle=\"--\")\n",
    "plt.xlim(-300, 4000)\n",
    "plt.savefig(\"fig1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the documentation: \"Rather than having this transformation applied automatically and without your knowledge, this package provides a few of the common transformations (e.g., hlog, tlog), but ultimately leaves it up to you to decide how to manipulate your data. In the hlog transformation, the parameter b controls the location where the transformation shifts from linear to log. The optimal value for this parameter depends on the range of your data. For smaller ranges, try smaller values of b. So if your population doesn’t show up well, just adjust b.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsample = sample.transform('hlog',channels=['FSC-A', 'FSC-H', 'FSC-W', 'SSC-A', 'SSC-H', 'SSC-W', 'Y2-A', 'Y2-H', 'Y2-W', 'B1-A', 'B1-H', 'B1-W'], b=500.0)\n",
    "tsample.plot('B1-A', color='blue', alpha=0.7, bins=100, grid=True)\n",
    "plt.axvline(1000, c=\"blue\", linestyle=\"--\")\n",
    "plt.savefig(\"fig2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data labeling (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## I'm going to use untransformed data for the supervised learning. Transformation just stretch the data but shouldn't \n",
    "## change the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classifyReadsThreshold(sample, channel, threshold):\n",
    "    # Classifying based on threshold\n",
    "    Object_Type = np.array([])\n",
    "    for i in sample.data[channel]:\n",
    "        if i > threshold:\n",
    "            Object_Type = np.append(Object_Type, 1)\n",
    "        else:\n",
    "            Object_Type = np.append(Object_Type, 9)\n",
    "    data = sample.data\n",
    "    data[\"Object_Type\"] = Object_Type\n",
    "    return data\n",
    "    \n",
    "channel = \"B1-A\"\n",
    "# Setting an arbitrary threshold for fluorescent and non-fluorescent stuff.\n",
    "threshold = 250\n",
    "\n",
    "data = classifyReadsThreshold(sample, channel, threshold)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noncells = data[data[\"Object_Type\"] == 9] \n",
    "noncells[\"B1-A\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here's what the manual cleaning did\n",
    "data_preprocessed = data[data[\"Object_Type\"] == 1] \n",
    "plt.grid()\n",
    "plt.hist(data[\"B1-A\"], color=\"#2F57FF\", bins = 100, label=\"Raw\");\n",
    "plt.hist(data_preprocessed[\"B1-A\"], bins=100, alpha= 0.5, color=\"orange\", label = \"Filtered\")\n",
    "plt.xlim(-300, 4000)\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"B1-A\")\n",
    "plt.legend()\n",
    "plt.savefig(\"fig3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "## Plotting relationship between each parameter that we'll use in machine learning\n",
    "channels_plot = list(tsample.channel_names[1:7]) + [\"Object_Type\"]\n",
    "data_plots = data[channels_plot]\n",
    "\n",
    "#plt.rcParams['axes.labelsize'] = 18\n",
    "#plt.rcParams['xtick.labelsize'] = 0\n",
    "#plt.rcParams['ytick.labelsize'] = 0\n",
    "\n",
    "\n",
    "#sns.pairplot(data_plots[9000:], hue=\"Object_Type\", size=3.5, x_vars=data_plots.columns[0:len(data_plots.columns)-1], y_vars=data_plots.columns[0:len(data_plots.columns)-1])\n",
    "#plt.savefig(\"fig4b.png\")\n",
    "#plt.rcdefaults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data for supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using supervised learning with all the scatter measurements, non transformed data\n",
    "X = sample.data[list(sample.channel_names[1:7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = data[\"Object_Type\"]\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping supervised learning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateModel(model, X_train, y_train):\n",
    "    model_trained = model.fit(X_train, y_train)\n",
    "    return model_trained\n",
    "\n",
    "def validateModel(model_trained, X_test, y_test):    \n",
    "    prediction = model_trained.predict(X_test)\n",
    "    accuracy = np.mean(prediction == y_test)\n",
    "    return accuracy \n",
    "\n",
    "def evaluateCleaning(model_trained, X_test, y_test, plot):\n",
    "    # Considering only non-cells\n",
    "    y_test_noncells = y_test[y_test == 9]\n",
    "    X_test_noncells = X_test.ix[y_test_noncells.index]\n",
    "    # Predicting\n",
    "    ## need to edit here so that it does PCA before predicting\n",
    "    prediction = model_trained.predict(X_test_noncells[list(X.columns[0:len(X.columns)-1])])\n",
    "\n",
    "    accuracy = np.mean(prediction == y_test_noncells)\n",
    "    # Computing % cleaned\n",
    "    X_test_noncells[\"Prediction\"] = prediction\n",
    "    X_test_noncells_predicted = X_test_noncells[X_test_noncells[\"Prediction\"] == 9]\n",
    "    percentCleaned = 100 * (X_test_noncells_predicted.shape[0]/float(X_test_noncells.shape[0]))\n",
    "    ## non cells predicted / total non cells : how many we can clean using a threshold\n",
    "    \n",
    "    # plotting\n",
    "    if plot == True:\n",
    "        plt.hist(X_test_noncells[\"B1-A\"], bins= 50, label = \"Non-Cells in Sample\");\n",
    "        plt.hist(X_test_noncells_filtered[\"B1-A\"], bins= 50, alpha= 0.5, color=\"orange\", label = \"Predicted Non-Cells\");\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.xlabel(\"B1-A\")\n",
    "        plt.legend()\n",
    "    \n",
    "    return percentCleaned\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(sample.channel_names[1:len(X.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def modelPerformance(model, X, test_fract, reps, pca):\n",
    "    accuracy = np.array([])\n",
    "    percentCleaned = np.array([])\n",
    "\n",
    "    for i in range(reps):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_fract)\n",
    "        \n",
    "        if pca == True:\n",
    "            X_train_PCA = PCA()\n",
    "            ## Using only scatter even if X has other stuff in it\n",
    "            X_train_red = X_train_PCA.fit_transform(X_train[list(X.columns[0:len(X.columns)-1])])\n",
    "            X_test_PCA = PCA()\n",
    "            X_test_red = X_test_PCA.fit_transform(X_test[list(X.columns[0:len(X.columns)-1])])\n",
    "            \n",
    "            model_trained = generateModel(model, X_train_red, y_train)\n",
    "            accuracy = np.append(accuracy, validateModel(model_trained, X_test_red, y_test))\n",
    "            ## need to edit evaluateCleaning so that it's agnostic on data going in: pca or no pca case?\n",
    "            return np.mean(accuracy)\n",
    "        \n",
    "        else:\n",
    "            ## train and predict, using all measurments but last (fluorescence that we use for classifying)\n",
    "            model_trained = generateModel(model, X_train[list(X.columns[0:len(X.columns)-1])], y_train)\n",
    "            accuracy = np.append(accuracy, validateModel(model_trained, X_test[list(X.columns[0:len(X.columns)-1])], y_test))\n",
    "            percentCleaned = np.append(percentCleaned, evaluateCleaning(model_trained, X_test, y_test, plot=False))\n",
    "    \n",
    "    if pca == True:\n",
    "        return np.mean(accuracy)\n",
    "    else:\n",
    "        return np.mean(accuracy), np.mean(percentCleaned)\n",
    "\n",
    "X = sample.data[list(sample.channel_names[1:7]) + [\"B1-A\"]]\n",
    "y = data[\"Object_Type\"]\n",
    "reps = 10\n",
    "test_fract = 0.2\n",
    "model = KNeighborsClassifier(n_neighbors=44)\n",
    "\n",
    "modelPerformance(model, X, test_fract, reps, pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import types \n",
    "\n",
    "def compareModelPerformance(models, X, test_fract, reps, plot, pca):\n",
    "    verbose = False\n",
    "    \n",
    "    accuracy_log = np.array([])\n",
    "    percentCleaned_log = np.array([])\n",
    "    \n",
    "    if type(models) <> list: models = [models]\n",
    "    \n",
    "    for model in models:\n",
    "        accuracy, percentCleaned = modelPerformance(model, X, test_fract, reps, pca)\n",
    "        accuracy_log = np.append(accuracy_log, accuracy)\n",
    "        percentCleaned_log = np.append(percentCleaned_log, percentCleaned)\n",
    "        if verbose == True:\n",
    "            print \"Completed step using model: \" + str(model)\n",
    "        \n",
    "    if plot == True:\n",
    "        print \"Still coding plotting fuction\"\n",
    "        # plotting function\n",
    "    return accuracy_log, percentCleaned_log\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sample.data[list(sample.channel_names[1:7]) + [\"B1-A\"]]\n",
    "reps = 100\n",
    "test_fract = 0.2\n",
    "models = [KNeighborsClassifier(n_neighbors=10), \n",
    "          KNeighborsClassifier(n_neighbors=44), \n",
    "          KNeighborsClassifier(n_neighbors=70),\n",
    "          LinearDiscriminantAnalysis(solver=\"svd\"),\n",
    "          LinearDiscriminantAnalysis(solver=\"lsqr\"),\n",
    "          DecisionTreeClassifier(max_depth=5),\n",
    "          DecisionTreeClassifier(max_depth=2),\n",
    "          DecisionTreeClassifier(),\n",
    "          GaussianMixture(covariance_type=\"spherical\"),\n",
    "          GaussianMixture(covariance_type=\"tied\"),\n",
    "          GaussianMixture(covariance_type=\"diag\"),\n",
    "          GaussianMixture(covariance_type=\"full\"),\n",
    "          RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "          RandomForestClassifier(),\n",
    "          MLPClassifier(alpha=1),\n",
    "          MLPClassifier(),\n",
    "          AdaBoostClassifier(),\n",
    "          GaussianNB(),\n",
    "          QuadraticDiscriminantAnalysis() \n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "accuracy_log_0, percentCleaned_log_0 = compareModelPerformance(models, X, test_fract, reps, plot=False, pca=False)\n",
    "# LDA parameters? solver = 'svd', 'lsqr'\n",
    "# SVC parameters? kernel = ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’\n",
    "# Gaussian mixtures: covariance-types cv_types = ['spherical', 'tied', 'diag', 'full'], n_components: try 1 to 7\n",
    "\n",
    "percentCleaned_log_0, accuracy_log_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelNames = [\"10-NN\", \"44-NN\", \"70-NN\", \"LDA-svd\", \"LDA-lsqr\", \"DT-d5\", \"DT-d2\", \"DT-dmax\",\"GM-sph\", \"GM-tied\", \"GM-diag\", \"GM-full\", \"RF-5-10-1\", \"RF\", \"NN-1\", \"NN\",\"AB\",\"NB\", \"QDA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see how the best model performs in cleaning the sample\n",
    "\n",
    "def cleanSampleIndex(model_trained, X, plot):\n",
    "    # need to create X with proper columns so that the last is B1\n",
    "    \n",
    "    prediction = model_trained.predict(X[list(X.columns[0:len(X.columns)-1])])\n",
    "    X[\"prediction\"] = prediction\n",
    "    X_cleaned = X[X[\"prediction\"] == 1]\n",
    "    \n",
    "    if plot == True:\n",
    "        plt.hist(X[\"B1-A\"], color=\"#2F57FF\", bins=100, label = \"Input data\")\n",
    "        plt.hist(X_cleaned[\"B1-A\"], bins=100, color=\"orange\", alpha= 0.8, label=\"Cleaned data\")\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"Counts\")\n",
    "        plt.xlabel(\"B1-A\")\n",
    "    \n",
    "    return X_cleaned\n",
    "\n",
    "X = sample.data[list(sample.channel_names[1:7]) + [\"B1-A\"]]\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model_trained = generateModel(model, X_train[list(sample.channel_names[1:len(X.columns)])], y_train)\n",
    "X_cleaned_i = cleanSampleIndex(model_trained, X, plot=True);\n",
    "plt.savefig(\"fig5.png\")\n",
    "\n",
    "X_cleaned = data.ix[X_cleaned_i.index]\n",
    "X_cleaned_noncells = X_cleaned[X_cleaned[\"Object_Type\"] == 9]\n",
    "1 - (X_cleaned_noncells.shape[0]/ float(data[data[\"Object_Type\"]== 9].shape[0]))\n",
    "## non cells cleaned = 1 - (remaining non cells after prediction / total non cells) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Positive control: including a second fluorescent reporter in model training. Does this improve percentCleaned?\n",
    "X = sample.data[list(sample.channel_names[1:7]) + [\"Y2-A\"] + [\"B1-A\"]]\n",
    "accuracy_log_1, percentCleaned_log_1 = compareModelPerformance(models, X, test_fract, reps, plot=False, pca=False)\n",
    "\n",
    "# Yes, we get up to 96% cleaning with decition tree classifiers. This is telling us that the alogorithm is working well,\n",
    "# but the scattering measurements don't have enough information to prperly classify non-cells reads (or that they're\n",
    "# very similar to cell reads)\n",
    "percentCleaned_log_1, accuracy_log_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here is the performance of the model using Y2-A\n",
    "X = sample.data[list(sample.channel_names[1:7]) + [\"Y2-A\"] + [\"B1-A\"]]\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model_trained = generateModel(model, X_train[list(sample.channel_names[1:len(X.columns)])], y_train)\n",
    "cleanSampleIndex(model_trained, X, plot=True);\n",
    "plt.savefig(\"fig6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is there a relationship between each single parameter and objectype? \n",
    "\n",
    "#sns.pairplot(data_plots[9000:],aspect=3, hue=\"Object_Type\", x_vars=\"Object_Type\", y_vars=data_plots.columns[0:len(data_plots.columns)-1]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generating datasets for single parameters        \n",
    "X = sample.data[[sample.channel_names[1]] + [\"B1-A\"]]\n",
    "accuracy_log, percentCleaned_log = compareModelPerformance(models, X, test_fract, reps, plot=False, pca=False)\n",
    "\n",
    "accuracy_table = accuracy_log*100\n",
    "percentCleaned_table = percentCleaned_log\n",
    "\n",
    "for i in list(sample.channel_names[2:10]):\n",
    "    X = sample.data[[i] + [\"B1-A\"]]    \n",
    "    accuracy_log, percentCleaned_log = compareModelPerformance(models, X, test_fract, reps, plot=False, pca=False)\n",
    "        \n",
    "    accuracy_table = np.vstack([accuracy_table, accuracy_log*100])\n",
    "    percentCleaned_table = np.vstack([percentCleaned_table, percentCleaned_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_table = pd.DataFrame(accuracy_table, columns=modelNames, index=list(sample.channel_names[1:10]))\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentCleaned_table = pd.DataFrame(percentCleaned_table, columns=modelNames, index=list(sample.channel_names[1:10]))\n",
    "percentCleaned_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding previous all scatter and all scatter + Y2-A results to the table\n",
    "accuracy_table_01= np.vstack([accuracy_log_0, accuracy_log_1])\n",
    "percentCleaned_table_01= np.vstack([percentCleaned_log_0, percentCleaned_log_1])\n",
    "\n",
    "accuracy_table_01 = pd.DataFrame(accuracy_table_01, columns=modelNames, index=[\"All Scatter\", \"All Scatter + Y-2A\"])\n",
    "percentCleaned_table_01 = pd.DataFrame(percentCleaned_table_01, columns=modelNames, index=[\"All Scatter\", \"All Scatter + Y-2A\"])\n",
    "\n",
    "accuracy_table_all = pd.concat([accuracy_table_01*100, accuracy_table])\n",
    "percentCleaned_table_all = pd.concat([percentCleaned_table_01, percentCleaned_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot it out\n",
    "# code adapted from here http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(percentCleaned_table_all, cmap=plt.cm.Blues, alpha=0.8)\n",
    "\n",
    "# Format\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6, 4)\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "ax.set_yticks(np.arange(percentCleaned_table_all.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticks(np.arange(percentCleaned_table_all.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "ax.set_xticklabels(modelNames, minor=False)\n",
    "ax.set_yticklabels(percentCleaned_table_all.index, minor=False)\n",
    "plt.xticks(rotation=60)\n",
    "ax.grid(False)\n",
    "\n",
    "# need to move title\n",
    "# need to add legend\n",
    "ax.set_title(\"Percent non-cells cleaned\", y=-0.15, fontweight=\"bold\", fontsize=15)\n",
    "plt.colorbar(heatmap)\n",
    "plt.savefig(\"heatmap-percentCleaned.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot it out\n",
    "# code adapted from here http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(accuracy_table_all, cmap=plt.cm.Blues, alpha=0.8)\n",
    "\n",
    "# Format\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "ax.set_yticks(np.arange(accuracy_table_all.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticks(np.arange(accuracy_table_all.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "ax.set_xticklabels(modelNames, minor=False)\n",
    "ax.set_yticklabels(accuracy_table_all.index, minor=False)\n",
    "plt.xticks(rotation=60)\n",
    "ax.grid(False)\n",
    "\n",
    "ax.set_title(\"Accuracy\", y=-0.15, fontweight=\"bold\", fontsize=15)\n",
    "plt.colorbar(heatmap)\n",
    "plt.savefig(\"heatmap-accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conclusion: most of the performance is explained by the Y2 channel.\n",
    "# None of the single parameters, other than Y2-A are good enough for triggering.\n",
    "# Using scatter + Y2-A actually performes worse that Y2-A alone, suggesting the other measurements \n",
    "# might be confounding the data\n",
    "\n",
    "\n",
    "# SVM crashed my computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the model to a new sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Opening a new file and checking that the threshold still works\n",
    "datafile2 = \"data/JF2017-01-06-B.0007.fcs\"\n",
    "sample2 = flow.FCMeasurement(ID='MG1655_sfGFP_mRFP1', datafile=datafile)\n",
    "sample2.plot('B1-A', color='blue', alpha=0.7, bins=100, grid=True)\n",
    "plt.axvline(250, c=\"blue\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training on the sample we used so far\n",
    "X = sample.data[list(sample.channel_names[1:7]) + [\"B1-A\"]]\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "model_trained = generateModel(model, X[list(sample.channel_names[1:len(X.columns)])], y)\n",
    "\n",
    "\n",
    "# generating dataset for new sample\n",
    "channel = \"B1-A\"\n",
    "# Setting an arbitrary threshold for fluorescent and non-fluorescent stuff.\n",
    "threshold = 250\n",
    "data2 = classifyReadsThreshold(sample2, channel, threshold)\n",
    "X2 = sample2.data[list(sample2.channel_names[1:7]) + [\"B1-A\"]]\n",
    "\n",
    "# cleaning new sample\n",
    "X2_cleaned_i = cleanSampleIndex(model_trained, X2, plot=True);\n",
    "\n",
    "print X2_cleaned_i.shape[0]\n",
    "\n",
    "\n",
    "X2_cleaned = data.ix[X2_cleaned_i.index]\n",
    "X2_cleaned_noncells = X2_cleaned[X2_cleaned[\"Object_Type\"] == 9]\n",
    "# 1 - (X2_cleaned_noncells.shape[0]/ float(data2[data2[\"Object_Type\"]== 9].shape[0]))\n",
    "\n",
    "# very high cleaning accuracy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sample.data[list(sample.channel_names[1:7]) + [\"Y2-A\"] + [\"B1-A\"]]\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model_trained = generateModel(model, X[list(sample.channel_names[1:len(X.columns)])], y)\n",
    "\n",
    "\n",
    "X2 = sample2.data[list(sample2.channel_names[1:7]) + [\"Y2-A\"] + [\"B1-A\"]]\n",
    "\n",
    "\n",
    "# cleaning new sample\n",
    "X2_cleaned_i = cleanSampleIndex(model_trained, X2, plot=True);\n",
    "\n",
    "print X2_cleaned_i.shape[0]\n",
    "\n",
    "X2_cleaned = data.ix[X2_cleaned_i.index]\n",
    "X2_cleaned_noncells = X2_cleaned[X2_cleaned[\"Object_Type\"] == 9]\n",
    "#1 - (X2_cleaned_noncells.shape[0]/ float(data2[data2[\"Object_Type\"]== 9].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting and comparison between classifiers\n",
    "[Compare classifiers](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py)\n",
    "[Plot decision boundaries](http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
